{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "\n",
    "class GeneralPPS:\n",
    "    @staticmethod\n",
    "    def map_columns(df, column_dict):\n",
    "        df.columns = [column_dict[col] for col in df.columns]\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_zero(df):\n",
    "        columns = [\"volume\", \"open\", \"low\", \"high\", \"close\"]\n",
    "        for column in columns:\n",
    "            df = df[df[column] != 0]\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    class DROP_LACK_DATA:\n",
    "        def __init__(self, df, percentage) -> None:\n",
    "            self.df = df\n",
    "            self.percentage = percentage\n",
    "\n",
    "        def get_ticker_count_series(self):\n",
    "            df = self.df\n",
    "            ticker_count_series = df.groupby(\"ticker\").count()[\"date\"]\n",
    "            return ticker_count_series\n",
    "\n",
    "        def get_available_tickers(self, ticker_count_series):\n",
    "            percentage = self.percentage\n",
    "\n",
    "            available_tickers = ticker_count_series[\n",
    "                ticker_count_series > ticker_count_series.max() * percentage\n",
    "            ].index\n",
    "            return available_tickers\n",
    "\n",
    "        def filter_available_tickers(self, available_tickers):\n",
    "            df = self.df\n",
    "            df = df[df[\"ticker\"].isin(available_tickers)]\n",
    "            return df\n",
    "\n",
    "        def __call__(self):\n",
    "            ticker_count_series = self.get_ticker_count_series()\n",
    "            available_tickers = self.get_available_tickers(ticker_count_series)\n",
    "            df = self.filter_available_tickers(available_tickers)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(arraylist, CFG):\n",
    "    i_window = CFG[\"input_window\"]\n",
    "    o_window = CFG[\"output_window\"]\n",
    "\n",
    "    x_dataset = list()\n",
    "    y_dataset = list()\n",
    "\n",
    "    for dataset_idx in range(len(arraylist) - i_window - o_window + 1):\n",
    "        _x = arraylist[dataset_idx : dataset_idx + i_window]\n",
    "        _y = arraylist[dataset_idx + i_window : dataset_idx + i_window + o_window]\n",
    "        x_dataset.append(_x)\n",
    "        y_dataset.append(_y)\n",
    "\n",
    "    x_dataset = np.array(x_dataset)\n",
    "    y_dataset = np.array(y_dataset)\n",
    "    final_x = arraylist[-i_window:]\n",
    "    return x_dataset, y_dataset, final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model dataset\n",
    "def sort_dataset_by_date(dataset, column=\"date\"):\n",
    "    sorted_dataset = dataset.sort_values(column)\n",
    "    return sorted_dataset\n",
    "\n",
    "\n",
    "def append_price_diff(dataset, open_col=\"open\", close_col=\"close\"):\n",
    "    dataset[\"price_diff\"] = (dataset[open_col] - dataset[close_col]) / dataset[open_col]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_array_list(dataset, column):\n",
    "    _arraylist = dataset[column].values\n",
    "    return _arraylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "# Similarity_model\n",
    "def get_cosine_similarity(array_1, array_2):\n",
    "    cosine_similarity = np.dot(array_1, array_2) / (\n",
    "        np.linalg.norm(array_1) * np.linalg.norm(array_2)\n",
    "    )\n",
    "    return cosine_similarity\n",
    "\n",
    "\n",
    "def get_similarity_df(x_dataset, y_dataset, final_x):\n",
    "    similarity_results = list()\n",
    "    for x_data, y_data in zip(x_dataset, y_dataset):\n",
    "        _similarity_score = get_cosine_similarity(x_data, final_x)\n",
    "        similarity_results.append(\n",
    "            {\n",
    "                \"similarity_score\": _similarity_score,\n",
    "                \"actual_y\": y_data,\n",
    "            }\n",
    "        )\n",
    "    similarity_df = pd.DataFrame(similarity_results)\n",
    "    return similarity_df\n",
    "\n",
    "\n",
    "def get_y_pred(similarity_df):\n",
    "    similarity_main_df = similarity_df.nlargest(5, \"similarity_score\")\n",
    "    y_pred = (\n",
    "        similarity_main_df[\"similarity_score\"] * similarity_main_df[\"actual_y\"]\n",
    "    ).mean()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "\n",
    "raw_train = pd.read_csv(\"./data/raw_data/train.csv\")\n",
    "raw_submission = pd.read_csv(\"./data/raw_data/sample_submission.csv\")\n",
    "\n",
    "with open(\"./data/assets/column_dict.json\", \"r\") as f:\n",
    "    column_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = raw_train.copy()\n",
    "submission = raw_submission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_pps = GeneralPPS()\n",
    "\n",
    "datasets = general_pps.map_columns(datasets, column_dict)\n",
    "datasets = general_pps.drop_zero(datasets)\n",
    "datasets = general_pps.DROP_LACK_DATA(datasets, 0.8)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1947/1947 [01:16<00:00, 25.32it/s]\n"
     ]
    }
   ],
   "source": [
    "CFG = {\n",
    "    \"input_window\": 15,\n",
    "    \"output_window\": 15,\n",
    "}\n",
    "tickers = sorted(set(datasets[\"ticker\"]))\n",
    "\n",
    "datasets_list = list()\n",
    "\n",
    "for ticker in tqdm(tickers):\n",
    "    _dataset = datasets[datasets[\"ticker\"] == ticker]\n",
    "\n",
    "    _dataset = sort_dataset_by_date(_dataset, \"date\")\n",
    "    _dataset = append_price_diff(_dataset, \"open\", \"close\")\n",
    "\n",
    "    _price_diff_arraylist = get_array_list(_dataset, \"price_diff\")\n",
    "\n",
    "    x_dataset, y_dataset, final_x = get_x_y(_price_diff_arraylist, CFG)\n",
    "    y_dataset = y_dataset.sum(axis=1)\n",
    "    _ticker_df = pd.DataFrame([[[x] for x in x_dataset], y_dataset]).T\n",
    "    _ticker_df.columns = [\"x\", \"y\"]\n",
    "    _ticker_df[\"x\"] = _ticker_df[\"x\"].apply(lambda x: x[0])\n",
    "\n",
    "    datasets_list.append(_ticker_df)\n",
    "\n",
    "datasets_df = pd.concat(datasets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1947/1947 [02:40<00:00, 12.13it/s]\n"
     ]
    }
   ],
   "source": [
    "ticker_pred_dict = dict()\n",
    "\n",
    "for ticker in tqdm(tickers):\n",
    "    _dataset = datasets[datasets[\"ticker\"] == ticker]\n",
    "    _dataset = sort_dataset_by_date(_dataset, \"date\")\n",
    "    _dataset = append_price_diff(_dataset, \"open\", \"close\")\n",
    "\n",
    "    _price_diff_arraylist = get_array_list(_dataset, \"price_diff\")\n",
    "    final_x = _price_diff_arraylist[-CFG[\"input_window\"] :]\n",
    "    _datasets_df = datasets_df.sample(10000)\n",
    "\n",
    "    _datasets_df[\"score\"] = _datasets_df[\"x\"].apply(\n",
    "        lambda x: get_cosine_similarity(x, final_x)\n",
    "    )\n",
    "    datasets_main_df = _datasets_df.nlargest(5, \"score\")\n",
    "    pred_y = (datasets_main_df[\"y\"] * datasets_main_df[\"score\"]).mean()\n",
    "    ticker_pred_dict[ticker] = pred_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
